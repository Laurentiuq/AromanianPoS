{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(repr=True)\n",
    "class Word2VecParams:\n",
    "\n",
    "    # skipgram parameters\n",
    "    MIN_FREQ = 50 \n",
    "    SKIPGRAM_N_WORDS = 5\n",
    "    T = 85\n",
    "    NEG_SAMPLES = 50\n",
    "    NS_ARRAY_LEN = 5_000_000\n",
    "    SPECIALS = \"\"\n",
    "    TOKENIZER = 'basic_english'\n",
    "\n",
    "    # network parameters\n",
    "    BATCH_SIZE = 100\n",
    "    EMBED_DIM = 300\n",
    "    EMBED_MAX_NORM = None\n",
    "    N_EPOCHS = 5\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    CRITERION = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Union' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mVocab\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecials\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstoi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m, in \u001b[0;36mVocab\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstoi) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_index\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: \u001b[43mUnion\u001b[49m[\u001b[38;5;28mstr\u001b[39m, List]):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(word, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstoi: \n",
      "\u001b[1;31mNameError\u001b[0m: name 'Union' is not defined"
     ]
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, list, specials):\n",
    "        self.stoi = {v[0]:(k, v[1]) for k, v in enumerate(list)}\n",
    "        self.itos = {k:(v[0], v[1]) for k, v in enumerate(list)}\n",
    "        self._specials = specials[0]\n",
    "        self.total_tokens = np.nansum(\n",
    "            [f for _, (_, f) in self.stoi.items()]\n",
    "            , dtype=int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stoi) - 1\n",
    "\n",
    "    def get_index(self, word: Union[str, List]):\n",
    "        if isinstance(word, str):\n",
    "            if word in self.stoi: \n",
    "                return self.stoi.get(word)[0]\n",
    "            else:\n",
    "                return self.stoi.get(self._specials)[0]\n",
    "        elif isinstance(word, list):\n",
    "            res = []\n",
    "            for w in word:\n",
    "                if w in self.stoi: \n",
    "                    res.append(self.stoi.get(w)[0])\n",
    "                else:\n",
    "                    res.append(self.stoi.get(self._specials)[0])\n",
    "            return res\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Word {word} is not a string or a list of strings.\"\n",
    "                )\n",
    "\n",
    "\n",
    "    def get_freq(self, word: Union[str, List]):\n",
    "        if isinstance(word, str):\n",
    "            if word in self.stoi: \n",
    "                return self.stoi.get(word)[1]\n",
    "            else:\n",
    "                return self.stoi.get(self._specials)[1]\n",
    "        elif isinstance(word, list):\n",
    "            res = []\n",
    "            for w in word:\n",
    "                if w in self.stoi:\n",
    "                    res.append(self.stoi.get(w)[1])\n",
    "                else:\n",
    "                    res.append(self.stoi.get(self._specials)[1])\n",
    "            return res\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Word {word} is not a string or a list of strings.\"\n",
    "                )\n",
    "    \n",
    "\n",
    "    def lookup_token(self, token: Union[int, List]):\n",
    "        if isinstance(token, (int, np.int64)):\n",
    "            if token in self.itos:\n",
    "                return self.itos.get(token)[0]\n",
    "            else:\n",
    "                raise ValueError(f\"Token {token} not in vocabulary\")\n",
    "        elif isinstance(token, list):\n",
    "            res = []\n",
    "            for t in token:\n",
    "                if t in self.itos:\n",
    "                    res.append(self.itos.get(token)[0])\n",
    "                else:\n",
    "                    raise ValueError(f\"Token {t} is not a valid index.\")\n",
    "            return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def yield_tokens(iterator, tokenizer):\n",
    "    r = re.compile('[a-z1-9]')\n",
    "    for text in iterator:\n",
    "        res = tokenizer(text)\n",
    "        res = list(filter(r.match, res))\n",
    "        yield res\n",
    "    \n",
    "def build_vocab(\n",
    "        iterator,\n",
    "        tokenizer, \n",
    "        params: Word2VecParams,\n",
    "        max_tokens: Optional[int] = None,\n",
    "    ):\n",
    "    counter = Counter()\n",
    "    for tokens in yield_tokens(iterator, tokenizer):\n",
    "        counter.update(tokens)\n",
    "\n",
    "    sorted_by_freq_tuples = sorted(\n",
    "        counter.items(), key=lambda x: (-x[1], x[0])\n",
    "        )\n",
    "\n",
    "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "    tokens = []\n",
    "    for token, freq in ordered_dict.items():\n",
    "        if freq >= params.MIN_FREQ:\n",
    "            tokens.append((token, freq))\n",
    "\n",
    "    specials = (params.SPECIALS, np.nan)\n",
    "    tokens[0] = specials\n",
    "\n",
    "    return Vocab(tokens, specials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_vocab(\"dataset/Tales.test.ro\", \"basic_english\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aromanianPos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
